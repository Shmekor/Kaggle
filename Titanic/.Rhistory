dist(irisSubset)
irisSubset = iris[,1:4]
hClustering = hclust(dist(irisSubset))
dist(irisSubset)
?dist
dist(irisSubset,method = "euclidean")
irisSubset = iris[,1:4]
hClustering = hclust(dist(irisSubset))
dist(irisSubset)
plot(hClustering)
?datasets
library(help="datasets")
hClustering
plot(hClustering)
fileUrl <- "https://spark-public.s3.amazonaws.com/dataanalysis/quiz3question4.rda"
download.file(fileUrl,destfile="./sparkdata1.csv")
list.files("./data")
?list.files
jopaData = read.csv("./data1.csv")
head(jopaData)
fileUrl <- "https://spark-public.s3.amazonaws.com/dataanalysis/quiz3question4.csv"
download.file(fileUrl,destfile="./sparkdata1.csv")
sparkData = read.csv("./sparkdata1.csv")
sparkData
?chwd
?plot
?plot(x,y)
?plot(x, y)
plot(x, y)
sparkData
plot(sparkData$x, sparkData$y)
kmeansObj = kmeans(sparkData,centers=2)
kmeansObj$cluster
plot(sparkData$x,sparkData$y,col=kmeansObj$cluster,pch=19,cex=2)
plot(sparkData$x, sparkData$y)
sparkData
kmeansObj = kmeans(data.frame(x=sparkData$x, y=sparkData$y),centers=2)
plot(sparkData$x,sparkData$y,col=kmeansObj$cluster,pch=19,cex=2)
points(kmeansObj$centers,col=1:3,pch=3,cex=3,lwd=3)
plot(sparkData$x, sparkData$y)
plot(sparkData$x,sparkData$y,col=kmeansObj$cluster,pch=19,cex=2)
plot(sparkData$x, sparkData$y)
plot(sparkData$x,sparkData$y,col=kmeansObj$cluster,pch=19,cex=2)
plot(sparkData$x, sparkData$y)
plot(sparkData$x,sparkData$y,col=kmeansObj$cluster,pch=19,cex=2)
points(kmeansObj$centers,col=1:3,pch=3,cex=3,lwd=3)
kmeansObj = kmeans(data.frame(x=sparkData$X, y=sparkData$x),centers=2)
plot(sparkData$x,sparkData$y,col=kmeansObj$cluster,pch=19,cex=2)
library(ElemStatLearn)
data(zip.train)
im = zip2image(zip.train,3)
image(im)
im = zip2image(zip.train,8)
image(im)
im = zip2image(zip.train,18)
image(im)
svd1 = svd(scale(zip.train))
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
im1 = zip2image(zip.train,8)
image(im1)
im2 = zip2image(zip.train,18)
image(im2)
svd1 = svd(im1)
svd2 = svd(im2)
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
plot(svd2$d^2/sum(svd2$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
par(mfcol=c(1, 2))
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
plot(svd2$d^2/sum(svd2$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
par(mfcol=c(2, 2))
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
plot(svd2$d^2/sum(svd2$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
plot(svd2$d^2/sum(svd2$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
plot(svd2$d^2/sum(svd2$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
par(mfcol=c(1, 2))
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
plot(svd2$d^2/sum(svd2$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
par(mfcol=c(2, 2))
image(im1)
image(im2)
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
plot(svd2$d^2/sum(svd2$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
approx1 <- svd1$u[,1] %*% t(svd1$v[,1]) * svd1$d[1]
approx2 <- svd2$u[,1] %*% t(svd2$v[,1]) * svd2$d[1]
plot(approx1)
image(approx1)
image(approx2)
image(approx1)
image(approx2)
par(mfrow=c(3, 2))
image(im1)
image(im2)
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
plot(svd2$d^2/sum(svd2$d^2),pch=19,xlab="Singluar vector",ylab="Variance explained")
image(approx1)
image(approx2)
approx5 <- svd2$u[,1:5] %*% diag(svd2$d[1:5])%*% t(svd2$v[,1:5])
image(approx5)
dim(im1)
dim(approx1)
im1[1,]
approx1[1,]
im1
approx1
head
fileUrl <- "https://spark-public.s3.amazonaws.com/dataanalysis/movies.txt"
download.file(fileUrl,destfile="./sparkdatalinear1.csv")
head
plot(galton$score,galton$box office,pch=19,col="blue")
lm1 <- lm(galton$box office ~ galton$score)
lines(galton$score,lm1$fitted,col="red",lwd=3)
plot(sparkdatalinear1$score,sparkdatalinear1$box office,pch=19,col="blue")
plot(sparkdatalinear1$score,sparkdatalinear1$boxoffice,pch=19,col="blue")
sparkDataLinear = read.csv("./sparkdata1.csv")
lm1 <- lm(sparkdatalinear$box office ~ sparkdatalinear$score)
lm1 <- lm(sparkdatalinear$boxoffice ~ sparkdatalinear$score)
plot(sparkdatalinear$score,sparkdatalinear$boxoffice,pch=19,col="blue")
plot(sparkdataLinear$score,sparkdataLinear$boxoffice,pch=19,col="blue")
plot(sparkDataLinear$score,sparkDataLinear$boxoffice,pch=19,col="blue")
lm1 <- lm(sparkDataLinear$boxoffice ~ sparkDataLinear$score)
lines(sparkDataLinear$score,lm1$fitted,col="red",lwd=3)
head(sparkDataLinear)
head(sparkDataLinear)
sparkDataLinear = read.csv("./sparkdatalinear1.csv")
head(sparkDataLinear)
sparkDataLinear$score
lm1 <- lm(sparkDataLinear$boxoffice ~ sparkDataLinear$score)
head(sparkDataLinear)
download.file(fileUrl,destfile="./sparkdatalinear1.txt")
sparkDataLinear = read.table("./sparkdatalinear1.txt")
?read.table
sparkDataLinear = read.csv("./sparkdatalinear1.txt", sep = '\t')
head(sparkDataLinear)
lm1 <- lm(sparkDataLinear$boxoffice ~ sparkDataLinear$score)
head(sparkDataLinear)
plot(sparkDataLinear$score,sparkDataLinear$box.office,pch=19,col="blue")
lm1 <- lm(sparkDataLinear$box.office ~ sparkDataLinear$score)
lines(sparkDataLinear$score,lm1$fitted,col="red",lwd=3)
?lines
lines.formula(sparkDataLinear)
lm1 <- lm(sparkDataLinear$box.office ~ sparkDataLinear$score)
plot(sparkDataLinear$score,sparkDataLinear$box.office,pch=19,col="blue")
lines(sparkDataLinear$score,lm1$fitted,col="red",lwd=3)
plot(sparkDataLinear$score,sparkDataLinear$box.office,pch=19,col="blue")
lm1 <- lm(sparkDataLinear$score ~ sparkDataLinear$box.office)
lines(sparkDataLinear$score,lm1$fitted,col="red",lwd=3)
lines(sparkDataLinear$box.office,lm1$fitted,col="red",lwd=3)
plot(sparkDataLinear$score,sparkDataLinear$box.office,pch=19,col="blue")
lm1 <- lm(sparkDataLinear$score ~ sparkDataLinear$box.office)
lines(sparkDataLinear$box.office,lm1$fitted,col="red",lwd=3)
summary(lm1)
plot(sparkDataLinear$score,sparkDataLinear$box.office,pch=19,col="blue")
lm1 <- lm(sparkDataLinear$score ~ sparkDataLinear$box.office)
lines(sparkDataLinear$box.office,lm1$fitted,col="red",lwd=3)
plot(sparkDataLinear$score,sparkDataLinear$box.office,pch=19,col="blue")
lines(sparkDataLinear$box.office,lm1$fitted,col="red",lwd=1)
summary(lm1)
confint(lm1,level=0.9)
summary(lm1)$coeff
confint(lm1,level=0.9)
summary(lm1)
lmBoth <- lm(sparkDataLinear$score ~ sparkDataLinear$box.office + sparkDataLinear$running.time)
plot(sparkDataLinear$box.office,sparkDataLinear$score,pch=19)
plot(sparkDataLinear$score,sparkDataLinear$box.office,pch=19,col="blue")
plot(sparkDataLinear$box.office,sparkDataLinear$score,pch=19)
points(hunger$Year,hunger$Numeric,pch=19,col=((hunger$Sex=="Male")*1+1))
plot(sparkDataLinear$box.office,sparkDataLinear$score,pch=19)
abline(c(lmBoth$coeff[1],lmBoth$coeff[2]),col="red",lwd=3)
abline(c(lmBoth$coeff[1] + lmBoth$coeff[3],lmBoth$coeff[2] ),col="black",lwd=3)
abline(c(lmBoth$coeff[1],lmBoth$coeff[2]),col="red",lwd=3)
summary(lm1)
abline(c(lmBoth$coeff[1] + lmBoth$coeff[3],lmBoth$coeff[2] ),col="black",lwd=3)
summary(lm)
summary(lm1)
summary(lmboth)
summary(lmboth)
lmBoth <- lm(sparkDataLinear$score ~ sparkDataLinear$box.office + sparkDataLinear$running.time)
plot(sparkDataLinear$box.office,sparkDataLinear$score,pch=19)
points(hunger$Year,hunger$Numeric,pch=19,col=((hunger$Sex=="Male")*1+1))
abline(c(lmBoth$coeff[1],lmBoth$coeff[2]),col="red",lwd=3)
summary(lmboth)
summary(lmBoth)
plot(sparkDataLinear$box.office,sparkDataLinear$score,pch=19)
plot(sparkDataLinear$running.time,sparkDataLinear$score,pch=19)
plot(sparkDataLinear$box.office,sparkDataLinear$score,pch=19)
plot(sparkDataLinear$running.time,sparkDataLinear$score,pch=19)
plot(sparkDataLinear$box.office,sparkDataLinear$score,pch=19)
plot(sparkDataLinear$running.time,sparkDataLinear$score,pch=19)
points(hunger$Year,hunger$Numeric,pch=19,col=((hunger$Sex=="Male")*1+1))
abline(c(lmBoth$coeff[1],lmBoth$coeff[2]),col="red",lwd=3)
summary(lmBoth)
abline(c(lmBoth$coeff[1] + lmBoth$coeff[3],lmBoth$coeff[2] ),col="black",lwd=3)
summary(lm1)
summary(lmboth)
summary(lmBoth)
plot(sparkDataLinear$running.time,sparkDataLinear$score,pch=19)
plot(sparkDataLinear$running.time,sparkDataLinear$score,pch=19)
summary(lmboth)
plot(sparkDataLinear$running.time,sparkDataLinear$score,pch=19)
summary(lmBoth)
lmBoth <- lm(sparkDataLinear$score ~ sparkDataLinear$box.office + sparkDataLinear$running.time[sparkDataLinear$running.time < 200])
rt200 <- sparkDataLinear$running.time < 200
lmBoth <- lm(sparkDataLinear$score[rt200] ~ sparkDataLinear$box.office[rt200] + sparkDataLinear$running.time[rt200])
plot(sparkDataLinear$box.office,sparkDataLinear$score,pch=19)
plot(sparkDataLinear$running.time,sparkDataLinear$score,pch=19)
plot(sparkDataLinear$running.time[rt200],sparkDataLinear$score,pch=19)
plot(sparkDataLinear$running.time[rt200],sparkDataLinear$score[rt200],pch=19)
lmBoth <- lm(sparkDataLinear$score[rt200] ~ sparkDataLinear$box.office[rt200] + sparkDataLinear$running.time[rt200])
abline(c(lmBoth$coeff[1],lmBoth$coeff[2]),col="red",lwd=3)
abline(c(lmBoth$coeff[1] + lmBoth$coeff[3],lmBoth$coeff[2] ),col="black",lwd=3)
lmBoth <- lm(sparkDataLinear$score ~ sparkDataLinear$box.office + sparkDataLinear$running.time)
plot(sparkDataLinear$box.office,sparkDataLinear$score,pch=19)
plot(sparkDataLinear$running.time,sparkDataLinear$score,pch=19)
plot(sparkDataLinear$box.office,sparkDataLinear$score,pch=19)
plot(sparkDataLinear$running.time,sparkDataLinear$score,pch=19)
plot(sparkDataLinear$box.office,sparkDataLinear$score,pch=19)
plot(sparkDataLinear$running.time,sparkDataLinear$score,pch=19)
plot(sparkDataLinear$running.time,sparkDataLinear$score,pch=19)
summary(lmBoth)
spData200 <- spData[sparkDataLinear$running.time < 200]
spData200 <- sparkDataLinear[sparkDataLinear$running.time < 200]
sparkDataLinear$running.time < 200
spData200 <- sparkDataLinear[sparkDataLinear$running.time < 200,]
lmBoth2 <- lm(spData200$score ~ spData200$box.office + spData200$running.time)
plot(spData200$box.office,spData200$score,pch=19)
plot(spData200$running.time,spData200$score,pch=19)
summary(lmBoth2)
summary(lmBoth)
lmBoth3 <- lm(sparkDataLinear$score ~ sparkDataLinear$rating + sparkDataLinear$running.time + sparkDataLinear$running.time*sparkDataLinear$rating)
summary(lmboth3)
summary(lmBoth3)
data(warpbreaks)
lm4 <- lm(sparkDataLinear$number.of.breaks ~ sparkDataLinear$tension)
head(data)
head(warpbreaks)
lm4 <- lm(warpbreaks$breaks ~ warpbreaks$tension)
confint(lm4,level=0.9)
confint(lm4,level=0.95)
summary(lmBoth3)
summary(lmBoth3)
lmBoth3 <- lm(sparkDataLinear$score ~ sparkDataLinear$rating + sparkDataLinear$running.time + (sparkDataLinear$running.time*sparkDataLinear$rating))
summary(lmBoth3)
lmBoth3 <- lm(sparkDataLinear$score ~ sparkDataLinear$rating + sparkDataLinear$running.time + sparkDataLinear$running.time*sparkDataLinear$rating)
summary(lmBoth3)
sparkDataLinear = read.csv("./sparkdatalinear1.txt", sep = '\t')
lmBoth3 <- lm(sparkDataLinear$score ~ sparkDataLinear$rating + sparkDataLinear$running.time + sparkDataLinear$running.time*sparkDataLinear$rating)
summary(lmBoth3)
lmBoth3 <- lm(sparkDataLinear$score ~ (sparkDataLinear$rating + sparkDataLinear$running.time) + sparkDataLinear$running.time*sparkDataLinear$rating)
summary(lmBoth3)
lmBoth3 <- lm(sparkDataLinear$score ~ sparkDataLinear$rating + sparkDataLinear$running.time + sparkDataLinear$rating * sparkDataLinear$running.time)
summary(lmBoth3)
head(sparkDataLinear)
summary(lmBoth3)
lmBoth3$coeff
1 - 0.6901
summary(lmBoth)
summary(lmBoth3)
1.1852 - 0.6901
confint(lm4,level=0.95)
summary(lm4)$coeff
data(warpbreaks)
head(warpbreaks)
lm4 <- lm(warpbreaks$breaks ~ warpbreaks$tension)
confint(lm4,level=0.95)
t <= confint(lm4,level=0.95)
t <- confint(lm4,level=0.95)
t
t
t[1,1]
t[2,1]
c(t[2,1], t[2,2]) - c(t[3,1], t[3,2])
(t[2,1] + t[2,2]) / 2
(t[3,1] + t[3,2]) / 2
install.packages('rmysql')
install.packages('rmysql')
install.packages('RMySQL')
?install.packages
install.packages('C:\Users\User.Mekor-PC\Downloads\RMySQL_0.9-3.tar.gz', repos=NULL, type='source')
install.packages('RMySQL_0.9-3.tar.gz', repos=NULL, type='source')
install.packages('RMySQL_0.9-3.tar.gz', repos=NULL, type='source')
install.packages('RMySQL', type='source')
library('RMySQL')
install.packages('RMySQL', type='source')
install.packages('RMySQL', type='source')
library('RMySQL')
install.packages('RMySQL', type='source')
library('RMySQL')
con2 <- dbConnect(MySQL(), user="root", password="129336", dbname="trend_analyzer", host="localhost")
dbListTables(con2)
kw <- dbGetQuery(con2 "SELECT * FROM (SELECT count(*) as kwc, ID_KEYWORD FROM trend_analyzer.table_document_keywords tdk
left join table_documents td ON td.ID=tdk.ID_DOCUMENT
WHERE td.PYEAR < 2008 and td.PYEAR != '' and td.PYEAR != 'Docu' group by ID_KEYWORD) a
JOIN table_keywords tk ON a.ID_KEYWORD=tk.ID WHERE kwc > 20 AND NAME != ''")
kw <- dbGetQuery(con2 "SELECT * FROM (SELECT count(*) as kwc, ID_KEYWORD FROM trend_analyzer.table_document_keywords tdk
left join table_documents td ON td.ID=tdk.ID_DOCUMENT
WHERE td.PYEAR < 2008 and td.PYEAR != '' and td.PYEAR != 'Docu' group by ID_KEYWORD) a
JOIN table_keywords tk ON a.ID_KEYWORD=tk.ID WHERE kwc > 20 AND NAME != ''")
kw <- dbGetQuery(con2 "SELECT * FROM (SELECT count(*) as kwc, ID_KEYWORD FROM trend_analyzer.table_document_keywords tdk left join table_documents td ON td.ID=tdk.ID_DOCUMENT WHERE td.PYEAR < 2008 and td.PYEAR != '' and td.PYEAR != 'Docu' group by ID_KEYWORD) a JOIN table_keywords tk ON a.ID_KEYWORD=tk.ID WHERE kwc > 20 AND NAME != ''")
kw <- dbGetQuery(con2 "SELECT * FROM (SELECT count(*) as kwc, ID_KEYWORD FROM trend_analyzer.table_document_keywords tdk
left join table_documents td ON td.ID=tdk.ID_DOCUMENT
WHERE td.PYEAR < 2008 and td.PYEAR != '' and td.PYEAR != 'Docu' group by ID_KEYWORD) a
JOIN table_keywords tk ON a.ID_KEYWORD=tk.ID WHERE kwc > 20 AND NAME != ''")
kw <- dbGetQuery(con2, "SELECT * FROM (SELECT count(*) as kwc, ID_KEYWORD FROM trend_analyzer.table_document_keywords group by ID_KEYWORD) a JOIN table_keywords tk ON a.ID_KEYWORD=tk.ID WHERE kwc > 15 AND NAME != ''")
kw <- dbGetQuery(con2 "SELECT * FROM (SELECT count(*) as kwc, ID_KEYWORD FROM trend_analyzer.table_document_keywords tdk
left join table_documents td ON td.ID=tdk.ID_DOCUMENT
WHERE td.PYEAR < 2008 and td.PYEAR != '' and td.PYEAR != 'Docu' group by ID_KEYWORD) a
JOIN table_keywords tk ON a.ID_KEYWORD=tk.ID WHERE kwc > 20 AND NAME != ''")
kw <- dbGetQuery(con2 "SELECT * FROM (SELECT count(*) as kwc, ID_KEYWORD FROM trend_analyzer.table_document_keywords tdk
left join table_documents td ON td.ID=tdk.ID_DOCUMENT WHERE td.PYEAR < 2008 and td.PYEAR != '' and td.PYEAR != 'Docu' group by ID_KEYWORD) a
JOIN table_keywords tk ON a.ID_KEYWORD=tk.ID WHERE kwc > 20 AND NAME != ''")
kw <- dbGetQuery(con2 "SELECT * FROM (SELECT count(*) as kwc, ID_KEYWORD FROM trend_analyzer.table_document_keywords tdk   left join table_documents td ON td.ID=tdk.ID_DOCUMENT WHERE td.PYEAR < 2008 and td.PYEAR != '' and td.PYEAR != 'Docu' group by ID_KEYWORD) a   JOIN table_keywords tk ON a.ID_KEYWORD=tk.ID WHERE kwc > 20 AND NAME != ''")
kw <- dbGetQuery(con2 "SELECT * FROM (SELECT count(*) as kwc, ID_KEYWORD FROM trend_analyzer.table_document_keywords tdk left join table_documents td ON td.ID=tdk.ID_DOCUMENT WHERE td.PYEAR < 2008 and td.PYEAR != '' and td.PYEAR != 'Docu' group by ID_KEYWORD) a JOIN table_keywords tk ON a.ID_KEYWORD=tk.ID WHERE kwc > 20 AND NAME != ''")
kw <- dbGetQuery(con2, "SELECT * FROM (SELECT count(*) as kwc, ID_KEYWORD FROM trend_analyzer.table_document_keywords group by ID_KEYWORD) a
JOIN table_keywords tk ON a.ID_KEYWORD=tk.ID WHERE kwc > 15 AND NAME != ''")
str(kw)
kw <- dbGetQuery(con2, "SELECT * FROM (SELECT count(*) as kwc, ID_KEYWORD FROM trend_analyzer.table_document_keywords tdk
left join table_documents td ON td.ID=tdk.ID_DOCUMENT
WHERE td.PYEAR < 2008 and td.PYEAR != '' and td.PYEAR != 'Docu' group by ID_KEYWORD) a
JOIN table_keywords tk ON a.ID_KEYWORD=tk.ID WHERE kwc > 20 AND NAME != ''")
kw[which(kw$ID == 10),]
nrow(kw)
kwMatrix = mat.or.vec(nrow(kw), nrow(kw))
kw$NAME
kw <- dbGetQuery(con2, "SELECT * FROM (SELECT count(*) as kwc, ID_KEYWORD FROM trend_analyzer.table_document_keywords tdk
left join table_documents td ON td.ID=tdk.ID_DOCUMENT
WHERE td.PYEAR < 2008 and td.PYEAR != '' and td.PYEAR != 'Docu' group by ID_KEYWORD) a
JOIN table_keywords tk ON a.ID_KEYWORD=tk.ID WHERE kwc > 5 AND NAME != ''")
nrow(kw)
kwMatrix = mat.or.vec(nrow(kw), nrow(kw))
kwNames <- kw$NAME
rownames(kwMatrix) <- kwNames
colnames(kwMatrix) <- kwNames
str(kwMatrix)
which(kwNames == 'Radiation')
setKw <- function(i, j) {
if(is.na(kwMatrix[i,j])) {
kwMatrix[i,j] <<- 1
} else {
kwMatrix[i,j] <<- kwMatrix[i,j] + 1
}
}
str(kwMatrix)
for(i in 1:nrow(documents)) {
docKw <- strsplit(documents[i, 'KWLIST'], ',')[[1]]
if(length(docKw) > 2) {
for(j in 1:(length(docKw) - 1)) {
kw1 <- kw[which(kw$ID == docKw[j]), 'NAME']
if(length(kw1) > 0) {
kw1MPos <- which(kwNames == kw1)
for(k in (j+1):length(docKw)) {
kw2 <- kw[which(kw$ID == docKw[k]), 'NAME']
if(length(kw2) > 0) {
kw2MPos <- which(kwNames == kw2)
setKw(kw1MPos, kw2MPos)
setKw(kw2MPos, kw1MPos)
}
}
}
}
}
}
documents <- dbGetQuery(con2, 'SELECT ID_DOCUMENT, GROUP_CONCAT(ID_KEYWORD) AS KWLIST FROM trend_analyzer.table_document_keywords GROUP BY ID_DOCUMENT')
str(documents)
for(i in 1:nrow(documents)) {
docKw <- strsplit(documents[i, 'KWLIST'], ',')[[1]]
if(length(docKw) > 2) {
for(j in 1:(length(docKw) - 1)) {
kw1 <- kw[which(kw$ID == docKw[j]), 'NAME']
if(length(kw1) > 0) {
kw1MPos <- which(kwNames == kw1)
for(k in (j+1):length(docKw)) {
kw2 <- kw[which(kw$ID == docKw[k]), 'NAME']
if(length(kw2) > 0) {
kw2MPos <- which(kwNames == kw2)
setKw(kw1MPos, kw2MPos)
setKw(kw2MPos, kw1MPos)
}
}
}
}
}
}
require('XML')
require('rgexf')
appendKw <- function(curValue, kw) {
if(curValue == '') {
kw
} else {
paste(curValue, kw, sep = ', ')
}
}
sourceV = c()
targetV = c()
weightsV = c()
for(i in 1:(nrow(kwMatrix) - 1)) {
for(j in (i+1):ncol(kwMatrix)) {
if(kwMatrix[i,j] > 0) {
sourceV <- append(sourceV, i)
targetV <- append(targetV, j)
weightsV <- append(weightsV, kwMatrix[i, j])
}
}
}
nodes <- data.frame(id=1:length(kwNames), label=kwNames, stringsAsFactors=F)
relations <- data.frame(source=sourceV, target=targetV)
write.gexf(nodes, relations, edgesWeight=weightsV, output = paste0('kwRelations', '_to2007', '.gexf'), defaultedgetype = 'undirected', keepFactors = FALSE)
kw <- dbGetQuery(con2, "SELECT * FROM (SELECT count(*) as kwc, ID_KEYWORD FROM trend_analyzer.table_document_keywords tdk
left join table_documents td ON td.ID=tdk.ID_DOCUMENT
WHERE td.PYEAR >= 2008 and td.PYEAR != '' and td.PYEAR != 'Docu' group by ID_KEYWORD) a
JOIN table_keywords tk ON a.ID_KEYWORD=tk.ID WHERE kwc > 5 AND NAME != ''")
kw <- dbGetQuery(con2, "SELECT * FROM (SELECT count(*) as kwc, ID_KEYWORD FROM trend_analyzer.table_document_keywords tdk
left join table_documents td ON td.ID=tdk.ID_DOCUMENT
WHERE td.PYEAR >= 2008 and td.PYEAR != '' and td.PYEAR != 'Docu' group by ID_KEYWORD) a
JOIN table_keywords tk ON a.ID_KEYWORD=tk.ID WHERE kwc > 10 AND NAME != ''")
kw <- dbGetQuery(con2, "SELECT * FROM (SELECT count(*) as kwc, ID_KEYWORD FROM trend_analyzer.table_document_keywords tdk
left join table_documents td ON td.ID=tdk.ID_DOCUMENT
WHERE td.PYEAR >= 2008 and td.PYEAR != '' and td.PYEAR != 'Docu' group by ID_KEYWORD) a
JOIN table_keywords tk ON a.ID_KEYWORD=tk.ID WHERE kwc > 5 AND NAME != ''")
nrow(kw)
kwMatrix = mat.or.vec(nrow(kw), nrow(kw))
kwNames <- kw$NAME
rownames(kwMatrix) <- kwNames
colnames(kwMatrix) <- kwNames
str(kwMatrix)
documents <- dbGetQuery(con2, 'SELECT ID_DOCUMENT, GROUP_CONCAT(ID_KEYWORD) AS KWLIST FROM trend_analyzer.table_document_keywords GROUP BY ID_DOCUMENT')
str(documents)
for(i in 1:nrow(documents)) {
docKw <- strsplit(documents[i, 'KWLIST'], ',')[[1]]
if(length(docKw) > 2) {
for(j in 1:(length(docKw) - 1)) {
kw1 <- kw[which(kw$ID == docKw[j]), 'NAME']
if(length(kw1) > 0) {
kw1MPos <- which(kwNames == kw1)
for(k in (j+1):length(docKw)) {
kw2 <- kw[which(kw$ID == docKw[k]), 'NAME']
if(length(kw2) > 0) {
kw2MPos <- which(kwNames == kw2)
setKw(kw1MPos, kw2MPos)
setKw(kw2MPos, kw1MPos)
}
}
}
}
}
}
sourceV = c()
targetV = c()
weightsV = c()
for(i in 1:(nrow(kwMatrix) - 1)) {
for(j in (i+1):ncol(kwMatrix)) {
if(kwMatrix[i,j] > 0) {
sourceV <- append(sourceV, i)
targetV <- append(targetV, j)
weightsV <- append(weightsV, kwMatrix[i, j])
}
}
}
nodes <- data.frame(id=1:length(kwNames), label=kwNames, stringsAsFactors=F)
relations <- data.frame(source=sourceV, target=targetV)
write.gexf(nodes, relations, edgesWeight=weightsV, output = paste0('kwRelations', '_from2007', '.gexf'), defaultedgetype = 'undirected', keepFactors = FALSE)
library('RMySQL')
library('RMySQL')
library('RMySQL')
require('XML')
?pbeta
library('caret')
library('Hmisc')
setwd("D:/Workspace/DataScience/Kaggle/Titanic")
source('R/prepareData.R')
dataSet <- read.csv('train.csv', stringsAsFactors=FALSE)
dataSetP <- prepareData(dataSet)
dataSetP$Survived <- as.factor(dataSetP$Survived)
dataSetP$SurvivedInt <- dataSet$Survived
inTrain <- createDataPartition(dataSetP$Survived, p=.75, list = FALSE)
trainDS <- dataSetP[inTrain,]
testDS <- dataSetP[-inTrain,]
source('model.splitBySex.R')
source('R/model.splitBySex.R')
sbsTrain <- model.splitBySex.train(trainDS)
sbsTrain
predictTest <- model.splitBySex.predict(testDS, sbsTrain)
confusionMatrix(predictTest$SPredicted, predictTest$Survived)
source('kaggle.submit.R')
source('R/kaggle.submit.R')
kaggle.submit(model.splitBySex.predict, sbsTrain)
source('R/prepareData.R')
dataSet <- read.csv('train.csv', stringsAsFactors=FALSE)
dataSetP <- prepareData(dataSet)
source('R/prepareData.R')
dataSetP <- prepareData(dataSet)
dataSetP$Survived <- as.factor(dataSetP$Survived)
dataSetP$SurvivedInt <- dataSet$Survived
#train
inTrain <- createDataPartition(dataSetP$Survived, p=.75, list = FALSE)
trainDS <- dataSetP[inTrain,]
testDS <- dataSetP[-inTrain,]
source('R/model.splitBySex.R')
sbsTrain <- model.splitBySex.train(trainDS)
sbsTrain
predictTest <- model.splitBySex.predict(testDS, sbsTrain)
confusionMatrix(predictTest$SPredicted, predictTest$Survived)
source('R/kaggle.submit.R')
kaggle.submit(model.splitBySex.predict, sbsTrain)
predictTrain <- model.splitBySex.predict(trainDS, sbsTrain)
confusionMatrix(predictTrain$SPredicted, predictTrain$Survived)
sbsTrain <- model.splitBySex.train(dataSetP)
sbsTrain
source('R/kaggle.submit.R')
kaggle.submit(model.splitBySex.predict, sbsTrain)
